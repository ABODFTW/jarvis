
import logging
import time

import speech_recognition as sr
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate

from llm import llm
from local_whisper import recognize_whisper
from tools.arp_scan import arp_scan_terminal
from tools.duckduckgo import duckduckgo_search_tool
from tools.matrix import matrix_mode
from tools.OCR import read_text_from_latest_image
from tools.screenshot import take_screenshot

# importing tools
from tools.time import get_time
from tts import speak_text

# importing tools

MIC_INDEX = None
TRIGGER_WORD = "jarvis"
CONVERSATION_TIMEOUT = 30  # seconds of inactivity before exiting conversation mode


logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.DEBUG)  # logging

# api_key = os.getenv("OPENAI_API_KEY") removed because it's not needed for ollama
# org_id = os.getenv("OPENAI_ORG_ID") removed because it's not needed for ollama

recognizer = sr.Recognizer()
mic = sr.Microphone(device_index=MIC_INDEX)

# Tool list
tools = [
    get_time,
    arp_scan_terminal,
    read_text_from_latest_image,
    duckduckgo_search_tool,
    matrix_mode,
    take_screenshot,
]

# Tool-calling prompt
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are Jarvis, an intelligent, conversational AI assistant. Your goal is to be helpful, friendly, and informative. You can respond in natural, human-like language and use tools when needed to answer questions more accurately. Always explain your reasoning simply when appropriate, and keep your responses conversational and concise.",
        ),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# Agent + executor
agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)



# Main interaction loop
def agent_loop():
    conversation_mode = False
    last_interaction_time = None

    try:
        with mic as source:
            recognizer.adjust_for_ambient_noise(source)
            while True:
                try:
                    if not conversation_mode:
                        logger.info("üé§ Listening for wake word...")
                        audio = recognizer.listen(source, timeout=10)
                        transcript = recognize_whisper(audio, language="en")
                        logger.info(f"üó£ Heard: {transcript}")

                        if TRIGGER_WORD.lower() in transcript.lower():
                            logger.info(f"üó£ Triggered by: {transcript}")
                            speak_text("Yes sir?")
                            conversation_mode = True
                            last_interaction_time = time.time()
                        else:
                            logger.debug("Wake word not detected, continuing...")
                    else:
                        logger.info("üé§ Listening for next command...")
                        audio = recognizer.listen(source, timeout=10)
                        command = recognize_whisper(audio, language="en")
                        logger.info(f"üì• Command: {command}")

                        logger.info("ü§ñ Sending command to agent...")
                        response = executor.invoke({"input": command})
                        content = response["output"]
                        logger.info(f"‚úÖ Agent responded: {content}")

                        print("Jarvis:", content)
                        speak_text(content)
                        last_interaction_time = time.time()

                        if time.time() - last_interaction_time > CONVERSATION_TIMEOUT:
                            logger.info("‚åõ Timeout: Returning to wake word mode.")
                            conversation_mode = False

                except sr.WaitTimeoutError:
                    logger.warning("‚ö†Ô∏è Timeout waiting for audio.")
                    if (
                        conversation_mode
                        and time.time() - last_interaction_time > CONVERSATION_TIMEOUT
                    ):
                        logger.info(
                            "‚åõ No input in conversation mode. Returning to wake word mode."
                        )
                        conversation_mode = False
                except sr.UnknownValueError:
                    logger.warning("‚ö†Ô∏è Could not understand audio.")
                except Exception as e:
                    logger.exception(f"‚ùå Error during recognition or tool call: {e}")
                    time.sleep(1)

    except Exception as e:
        logger.critical(f"‚ùå Critical error in main loop: {e}")
